{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18. 23. 22.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "def ucb(v, n, t, c_param=1):\n",
    "    '''\n",
    "    t visits to state node, n visits to an action under the state node, total value v\n",
    "    '''\n",
    "    return np.inf if (t == 0 or n == 0) else ((v/n) + c_param * math.sqrt(2*math.log(t)/n))\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state      # State (s)\n",
    "        self.parent = parent    # Parent node\n",
    "        self.children = {}      # Dictionary to hold child nodes (action -> child node)\n",
    "        self.visits = 0         # Number of visits to this node\n",
    "        self.value = 0.0        # Accumulated value for this node\n",
    "        self.depth = 0 if parent is None else parent.depth + 1  # Node depth\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == len(Actions)  # All actions have been tried\n",
    "\n",
    "\n",
    "    def best_child(self, c_param=1.4):\n",
    "        #if self.visits == 0: # To fix the UCB calculation if self has had no visits\n",
    "            #choices_weights = [\n",
    "                #(child.value / child.visits)\n",
    "                #for child in self.children.values()\n",
    "            #]\n",
    "        #else:\n",
    "            #choices_weights = [\n",
    "                #(child.value / child.visits) + c_param * math.sqrt((2 * math.log(self.visits) / child.visits))\n",
    "                #for child in self.children.values()\n",
    "            #]\n",
    "\n",
    "        choices_weights = [\n",
    "                ucb(child.value, child.visits, self.visits, c_param) for child in self.children.values()\n",
    "            ]\n",
    "        return list(self.children.values())[np.argmax(choices_weights)]\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'd=%d n=%d v=%f' % (self.depth, self.visits, self.value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'd=%d n=%d v=%f' % (self.depth, self.visits, self.value)\n",
    "\n",
    "def r(s):  # Immediate reward function\n",
    "    return float(s == 2)\n",
    "\n",
    "# State and action space\n",
    "States = np.array([0, 1, 2], dtype=int)\n",
    "Actions = np.array([0, 1], dtype=int)\n",
    "\n",
    "# Transition probability matrix P[a, s, s_next]\n",
    "P = np.array([\n",
    "    [0.8, 0.2, 0.0],\n",
    "    [0.1, 0.8, 0.1],\n",
    "    [0.0, 0.2, 0.8],\n",
    "    [0.2, 0.8, 0],\n",
    "    [0.0, 0.2, 0.8],\n",
    "    [0.0, 0.8, 0.2],\n",
    "]).reshape(2, 3, 3)\n",
    "\n",
    "gamma = 0.9  # Discount factor for future rewards\n",
    "max_depth = 30  # Maximum tree depth\n",
    "\n",
    "def simulate(state, depth):\n",
    "    \"\"\"Simulate a random rollout from the current state.\"\"\"\n",
    "    total_reward = 0.0\n",
    "    for d in range(depth):\n",
    "        action = random.choice(Actions)  # Choose a random action\n",
    "        reward = r(state)\n",
    "        total_reward += gamma**d * reward \n",
    "\n",
    "        next_state = np.random.choice(States, p=P[action, state])\n",
    "        state = next_state\n",
    "        if d == max_depth:  # Maximum depth\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def expand(node):\n",
    "    \"\"\"Expand the node by trying an untried action and creating a new child.\"\"\"\n",
    "    tried_actions = node.children.keys()\n",
    "    untried_actions = [a for a in Actions if a not in tried_actions]\n",
    "    action = random.choice(untried_actions)\n",
    "    \n",
    "    # Sample the next state based on transition probabilities\n",
    "    next_state = np.random.choice(States, p=P[action, node.state])\n",
    "    \n",
    "    # Apply immediate reward for the expanded node\n",
    "    reward = r(node.state)  # Immediate reward, no discounting here\n",
    "    \n",
    "    # Create a new child node\n",
    "    child_node = MCTSNode(state=next_state, parent=node)\n",
    "    node.children[action] = child_node\n",
    "    return child_node, reward\n",
    "\n",
    "def backpropagate_trajectory(trajectory, rollout_reward):\n",
    "    \"\"\"Backpropagate the reward through the trajectory with correct discounting.\"\"\"\n",
    "    cumulative_reward = rollout_reward  # Start with the rollout reward\n",
    "    for node, reward in reversed(trajectory):\n",
    "        # Add the immediate reward to the cumulative reward and propagate\n",
    "        cumulative_reward = reward + gamma * cumulative_reward\n",
    "        node.visits += 1\n",
    "        node.value += cumulative_reward\n",
    "\n",
    "def best_action(root, iterations=1000):\n",
    "    \"\"\"Perform MCTS and return the best action.\"\"\"\n",
    "    for i in range(iterations):\n",
    "        node = root\n",
    "        #print(i, root)\n",
    "        trajectory = []  # To store the nodes along the current path\n",
    "\n",
    "        # Selection: Traverse the tree to find a node that is not fully expanded\n",
    "        while node.is_fully_expanded() and node.children and node.depth < max_depth:\n",
    "            child = node.best_child()\n",
    "            reward = r(node.state)  # Immediate reward for the current node\n",
    "            trajectory.append((node, reward))  # Add the node and reward to the trajectory\n",
    "            node = child\n",
    "\n",
    "        # Expansion: Expand the node if it's not fully expanded\n",
    "        if not node.is_fully_expanded() and node.depth < max_depth:\n",
    "            child, expanded_reward = expand(node)\n",
    "            reward = expanded_reward  # Immediate reward for the expanded node\n",
    "            trajectory.append((node, reward))  # Add the expanded node and reward to the trajectory\n",
    "            node = child\n",
    "\n",
    "        # Simulation: Perform a random rollout from the newly expanded node\n",
    "        rollout_reward = simulate(node.state, max_depth - node.depth)\n",
    "        #print('before update', trajectory, rollout_reward)\n",
    "        \n",
    "        # Backpropagation: Backpropagate the reward through the trajectory\n",
    "        backpropagate_trajectory(trajectory, rollout_reward)\n",
    "        #print('after update', trajectory)\n",
    "\n",
    "    # Choose the action leading to the best child\n",
    "    best_action = max(root.children, key=lambda action: root.children[action].value / root.children[action].visits)\n",
    "    return best_action\n",
    "\n",
    "policy = [1, 1, 0] # optimal policy\n",
    "counts = np.zeros(3)\n",
    "# Run MCTS for each initial state and print the best action\n",
    "for initial_state in range(3):\n",
    "    for _ in range(30):\n",
    "        # Initial state\n",
    "        root = MCTSNode(state=initial_state)\n",
    "\n",
    "        # Run MCTS\n",
    "        best_act = best_action(root, iterations=10000)\n",
    "        counts[initial_state] += (best_act == policy[initial_state])\n",
    "        #print(f\"Best action from state {initial_state} is: {best_act}\")\n",
    "\n",
    "print(counts/30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8558bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6        0.76666667 0.73333333]\n"
     ]
    }
   ],
   "source": [
    "print(counts/30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
